import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
import warnings
from gensim.models import FastText

import time as t
warnings.filterwarnings("ignore")
from keras.layers import Dense,LSTM,SimpleRNN
from keras.models import Sequential
from keras.utils import np_utils
from keras.layers import Dropout

def kmerise(seq,k=10):
    kmers = []
    t = len(seq)
    l = 0
    while (l<t):
        kmers.append(seq[l:l+k])
        l=l+k
    return kmers

def ngrams(kmers_list,n=1):
    ngram = []
    for i in range(len(kmers_list)):
        t = kmers_list[i:i+n]
        if len(t)==n:
            ngram.append(t)
    return ngram

def ngram_probability(word,ngrams):
    return ngrams.count(word)/len(ngrams)
def probVec(ngrams):
    return [ngrams.count(i)/len(ngrams) for i in ngrams]

def create_sentences(tokenized_arr):
    max_l = 0
    all_sentence = []
    for i in tokenized_arr:
        st=""
        for j in i:
            st +=j+" "
        i_len = len(i)
        if i_len>max_l:
            max_l = i_len
        all_sentence.append(st)
    return all_sentence,max_l

mersSeq = pd.read_csv('C:/Users/Anuvarshini/Desktop/sem 4/IBS 19BIO211/MersSequences.csv')
sarsSeq = pd.read_csv('C:/Users/Anuvarshini/Desktop/sem 4/IBS 19BIO211/SarsSequences.csv')

print("MersSequences\n",mersSeq.head(),'\n')
print("SarsSequences\n",sarsSeq.head())

mersX = np.array(mersSeq['Sequence'])
sarsX = np.array(sarsSeq['Sequence'])

mersY = np.zeros((len(mersX),))
sarsY = np.ones((len(sarsX),))
k=40
mersk = [kmerise(i,k) for i in mersX]
sarsk = [kmerise(i,k) for i in sarsX]

model_mers = FastText(window=3, min_count=1)  
model_mers.build_vocab(mersk)
model_mers.train(mersk, total_examples=len(mersk), epochs=500)

model_sars = FastText(window=3, min_count=1)  
model_sars.build_vocab(sarsk)
model_sars.train(sarsk, total_examples=len(sarsk), epochs=500)

Mavg = np.zeros((len(mersk),100))
for i,m in enumerate(mersk):
    emb = [model_mers.wv[w] for w in mersk[i]] 
    Mavg[i] = np.mean(emb, axis=0)

Savg = np.zeros((len(sarsk),100))
for j,s in enumerate(sarsk):
    emb = [model_sars.wv[w] for w in sarsk[j]] 
    Savg[j] = np.mean(emb, axis=0)

Xt = np.vstack((Mavg, Savg))
X = Xt.reshape(Xt.shape+(1,))
Yt = np.append(np.zeros(len(Mavg)), np.ones(len(Savg)))
Y = np_utils.to_categorical(Yt+1)
trainx,testx,trainy,testy=train_test_split(X,Y,test_size=0.2)

print(trainx.shape)
print(Y.shape)
print(type(X))
print(type(Y))
print(type(testx))

model = Sequential()
model.add(LSTM(units = 50,dropout = 0.2, return_sequences = True, input_shape = (trainx.shape[1], 1), activation ='tanh'))
model.add(LSTM(units = 50, activation = 'tanh'))
# Adding the output layer
# For Full connection layer we use dense
model.add(Dense(units = 2,activation = 'softmax'))
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
model.fit(trainx,trainy,epochs=15,validation_data=(testx,testy),verbose=1)

model.summary()
loss,acc =model.evaluate(testx,testy,verbose =0)
